{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT\n",
    "import sys\n",
    "import pandas as pd\n",
    "#import numpy as np   \n",
    "import vcf \n",
    "import math  \n",
    "import pickle  \n",
    "import imp\n",
    "#import xgboost as xgb \n",
    "import f\n",
    "myargs=f.grab_bashscript_args('run_apply_3')\n",
    "## TODO\n",
    "## chage 'thresh' to 'pass_score'\n",
    "## mention indel capabilities in MS\n",
    "## chr21 test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRAB INPUT PARAMS\n",
    "jdict={1:'1_5',6:'6_15',16:'16_PLUS'}\n",
    "vartypes=['SNP','MNP']+[x+jdict[j] for x in ['I','D'] for j in [1,6,16]]\n",
    "if 1==1:\n",
    "    #myargs=sys.argv\n",
    "    infile=myargs[myargs.index('--vcf_in')+1]\n",
    "    outfile=myargs[myargs.index('--vcf_out')+1]\n",
    "    moddict={vartype:{zyg:[myargs[i+1] for i,x in enumerate(myargs) if x=='--modfile_'+vartype+'_'+zyg] for zyg in ['hom','het']} for vartype in vartypes}\n",
    "    threshdict={vartype:{zyg:float(myargs[myargs.index('--thresh_'+vartype+'_'+zyg)+1]) for zyg in ['het','hom']} for vartype in vartypes}\n",
    "else:\n",
    "    infile='/igm/home/jbg001/git/germfilt/germline_variant_filtering/kf/tm/temp.vcf.gz'\n",
    "    outfile='/igm/home/jbg001/git/germfilt/germline_variant_filtering/kf/tm/applied_filter.vcf'\n",
    "    moddict={x:{y:{} for y in ['hom','het']} for x in ['SNP','INDEL']}\n",
    "    moddict['SNP']['het']='/igm/projects/FOR_JEFF/germfilt/tm/batch_1_giab_1_02262020_v2/training/mod/mod_SNP_het_0/mod_0.pkl'\n",
    "    moddict['SNP']['hom']='/igm/projects/FOR_JEFF/germfilt/tm/batch_1_giab_1_02262020_v2/training/mod/mod_SNP_hom_1/mod_0.pkl'\n",
    "    moddict['INDEL']['het']='/igm/projects/FOR_JEFF/germfilt/tm/batch_1_giab_1_02262020_v2/training/mod/mod_INDEL_het_2/mod_0.pkl'\n",
    "    moddict['INDEL']['hom']='/igm/projects/FOR_JEFF/germfilt/tm/batch_1_giab_1_02262020_v2/training/mod/mod_INDEL_hom_3/mod_0.pkl'\n",
    "    threshdict={x:{y:{} for y in ['hom','het']} for x in ['SNP','INDEL']}\n",
    "    threshdict['SNP']['het']=0.75\n",
    "    threshdict['SNP']['hom']=0\n",
    "    threshdict['INDEL']['het']=0.25\n",
    "    threshdict['INDEL']['hom']=0\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD VCFs, SET INITIAL PREDS\n",
    "imp.reload(f)\n",
    "## LOAD VCFS\n",
    "if 1==1:\n",
    "    vcfdict={}\n",
    "    vcfdict['query']=f.grab_query_vcf_new(infile,0)\n",
    "    samps=vcfdict['query']['samples']\n",
    "    dfraw=vcfdict['query']['df']\n",
    "## IDENTIFY PROBLEMATIC INDS AT RECORD LEVEL...DEFINE ALT\n",
    "if 1==1:\n",
    "    multiallelic_inds=dfraw[dfraw.ALT_list.apply(len)>1].index\n",
    "    noalt_inds=dfraw[dfraw.ALT_list.apply(len)==0].index\n",
    "    dftemp=dfraw.loc[dfraw.index.difference(multiallelic_inds.union(noalt_inds))]\n",
    "    dftemp['ALT']=dftemp.ALT_list.apply(lambda x: x[0])\n",
    "    dftemp.loc[dftemp.ALT.isnull(),'ALT']='X'\n",
    "    dftemp['ALT']=dftemp['ALT'].apply(str)\n",
    "    weirdalt_inds=dftemp[dftemp['ALT'].apply(lambda x:x.replace('A','').replace('C','').replace('G','').replace('T','')).apply(len)>0].index\n",
    "## LOOK AT GENOTYPES, ASSIGN ZYG\n",
    "if 1==1:\n",
    "    zygdict={}\n",
    "    for samp in samps:\n",
    "        zygdict[samp]={}\n",
    "        gtcol='gtfeat_'+samp+'_GT'\n",
    "        gtlistcol='gtlist_'+samp\n",
    "        dftemp[gtlistcol]=dftemp[gtcol].apply(lambda x: [int(y) for y in x.replace('|','/').replace('.','0').split('/')])\n",
    "        nocallinds=dftemp[dftemp[gtlistcol].apply(max)==0].index\n",
    "        multiallelic_call_inds=dftemp[dftemp[gtlistcol].apply(max)>1].index\n",
    "        tossinds=nocallinds.union(multiallelic_call_inds)\n",
    "        hetinds=dftemp[dftemp[gtlistcol].apply(min)==0].index.difference(tossinds)\n",
    "        hominds=dftemp[dftemp[gtlistcol].apply(min)==1].index.difference(tossinds)\n",
    "        zygdict[samp]['het']=hetinds.difference(weirdalt_inds)\n",
    "        zygdict[samp]['hom']=hominds.difference(weirdalt_inds)\n",
    "        zygdict[samp]['nocall']=nocallinds\n",
    "    dfpre=dftemp.loc[dftemp.index.difference(weirdalt_inds)]\n",
    "# ASSIGN VARTYPES\n",
    "if 1==1:\n",
    "    for x in ['REF','ALT']:\n",
    "        dfpre[x+'_len']=dfpre[x].apply(len)\n",
    "    dfpre['len_diff']=dfpre['ALT_len']-dfpre['REF_len']\n",
    "    vtdict={}\n",
    "    vtdict['SNP']=dfpre[(dfpre.len_diff==0) & (dfpre.REF_len==1)].index\n",
    "    vtdict['MNP']=dfpre[(dfpre.len_diff==0) & (dfpre.REF_len>1)].index\n",
    "    cutoffdict=[1,6,16,10000000]\n",
    "    for cutoffind in range(len(cutoffdict)-1):\n",
    "        jlower=cutoffdict[cutoffind]\n",
    "        jupper=cutoffdict[cutoffind+1]\n",
    "        vtdict['I'+jdict[jlower]]=dfpre[(dfpre.len_diff >= jlower) & (dfpre.len_diff < jupper)].index\n",
    "        vtdict['D'+jdict[jlower]]=dfpre[(dfpre.len_diff <= -jlower) & (dfpre.len_diff > -jupper)].index\n",
    "    dfpre['vartype']=None\n",
    "    for x in vtdict:\n",
    "        dfpre.loc[vtdict[x],'vartype']=x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FEATS...INITIALIZE PREDS\n",
    "df = dfpre.where(pd.notnull(dfpre), None)\n",
    "df,sampfeats=f.grab_basefeats(df)\n",
    "for samp in samps:\n",
    "    df['gtfeat_'+samp+'_total_AD']=df[[x for x in df.columns if 'gtfeat_'+samp+'_AD_' in x]].apply('sum',axis=1)\n",
    "    df['yprob_'+samp]=0.0\n",
    "    df['ypred_'+samp]=0\n",
    "cutfeats=['gtfeat_PS']\n",
    "catfeats_hardcoded=['genfeat_REF', 'genfeat_ALT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying filter to SNP, het, Sample_Diag-excap51-HG004-EEogPU\n",
      "31176\n",
      "Applying filter to SNP, hom, Sample_Diag-excap51-HG004-EEogPU\n",
      "19423\n",
      "Applying filter to MNP, het, Sample_Diag-excap51-HG004-EEogPU\n",
      "Applying filter to MNP, hom, Sample_Diag-excap51-HG004-EEogPU\n",
      "Applying filter to I1_5, het, Sample_Diag-excap51-HG004-EEogPU\n",
      "1229\n",
      "Applying filter to I1_5, hom, Sample_Diag-excap51-HG004-EEogPU\n",
      "1022\n",
      "Applying filter to I6_15, het, Sample_Diag-excap51-HG004-EEogPU\n",
      "113\n",
      "Applying filter to I6_15, hom, Sample_Diag-excap51-HG004-EEogPU\n",
      "69\n",
      "Applying filter to I16_PLUS, het, Sample_Diag-excap51-HG004-EEogPU\n",
      "38\n",
      "Applying filter to I16_PLUS, hom, Sample_Diag-excap51-HG004-EEogPU\n",
      "18\n",
      "Applying filter to D1_5, het, Sample_Diag-excap51-HG004-EEogPU\n",
      "1810\n",
      "Applying filter to D1_5, hom, Sample_Diag-excap51-HG004-EEogPU\n",
      "815\n",
      "Applying filter to D6_15, het, Sample_Diag-excap51-HG004-EEogPU\n",
      "131\n",
      "Applying filter to D6_15, hom, Sample_Diag-excap51-HG004-EEogPU\n",
      "62\n",
      "Applying filter to D16_PLUS, het, Sample_Diag-excap51-HG004-EEogPU\n",
      "42\n",
      "Applying filter to D16_PLUS, hom, Sample_Diag-excap51-HG004-EEogPU\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "## MAIN LOOP\n",
    "for vartype in vartypes:\n",
    "    vardat=df.loc[vtdict[vartype]].copy()\n",
    "    catfeats=[]\n",
    "    if vartype=='SNP':\n",
    "        catfeats=catfeats_hardcoded\n",
    "    dummyvar=f.onehot_encode_cold_allvals(vardat,catfeats)\n",
    "    ## COMPUTE \n",
    "    for zyg in ['het','hom']:\n",
    "        for samp in samps:\n",
    "            print('Applying filter to '+ vartype + ', ' + zyg+', '+samp)\n",
    "            locdat_base=vardat.loc[vardat.index.intersection(zygdict[samp][zyg])]\n",
    "            if len(locdat_base)==0:\n",
    "                continue\n",
    "            featdict={x:x.replace('gtfeat_'+samp,'gtfeat') for x in locdat_base.columns if 'gtfeat_'+samp in x}\n",
    "            locdat=locdat_base.rename(columns=featdict)\n",
    "            print(len(locdat))\n",
    "            for modcount,modfile in enumerate(moddict[vartype][zyg]):\n",
    "                with open(modfile, 'rb') as ff:\n",
    "                    mymod = pickle.load(ff)\n",
    "                feats=mymod.get_booster().feature_names\n",
    "                if modcount==0:\n",
    "                    for x in feats:\n",
    "                        if x not in locdat.columns:\n",
    "                            locdat[x]=float('nan')\n",
    "                        locdat.loc[locdat[x].isnull(), x]=float('nan')\n",
    "                        locdat[x]=locdat[x].apply(float)\n",
    "                df.loc[locdat.index,'yprob_'+samp+'_'+str(modcount)]=mymod.predict_proba(locdat[feats])[:,1]\n",
    "            df.loc[locdat.index,'yprob_'+samp]=df.loc[locdat.index][['yprob_'+samp+'_'+str(modcount) for modcount in range(len(moddict[vartype][zyg]))]].apply('mean',axis=1)\n",
    "            df.loc[locdat.index,'ypred_'+samp]=1*(df.loc[locdat.index]['yprob_'+samp] >= threshdict[vartype][zyg])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD PREDICTIONS TO RAW DATAFRAME\n",
    "## PASS ALL MULTIALLELIC INDS \n",
    "## PASS ALL INDS WITH ALT CONTAINING NON ACGT CHARACTERS \n",
    "## (THE NOCALLS WERE MANUALLY FAILED IN THE MODEL-APPLICATION SETUP)\n",
    "multiallelic_inds,noalt_inds,weirdalt_inds\n",
    "for samp in samps:\n",
    "    predcol='ypred_'+samp\n",
    "    dfraw[predcol]=0\n",
    "    dfraw.loc[multiallelic_inds,predcol]=1 \n",
    "    dfraw.loc[weirdalt_inds,predcol]=1    \n",
    "    dfraw.loc[df.index,predcol]=df['ypred_'+samp]\n",
    "## PASS ALL POSITIONS WITH A PASSED VARIANT\n",
    "dfraw['ypred']=dfraw[['ypred_'+x for x in samps]].apply(max,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote annotated vcf to /igm/projects/FOR_JEFF/germfilt/tm/03062020_noon_noprepy_batch_3_giab_4/autofiltered_granular_train_032020_afternoon_appid_3.vcf\n"
     ]
    }
   ],
   "source": [
    "## WRITE OUTPUT\n",
    "## Write VCF\n",
    "predcodedict={0:'LowQual',1:'PASS'}\n",
    "vcf_reader = vcf.Reader(filename=infile,compressed=True)\n",
    "vcf_reader.filters['LowQual']=vcf_reader.filters[list(vcf_reader.filters.keys())[0]]._make(['LowQual','Flagged as low quality by AutoFilter models'])\n",
    "if 'PASS' not in vcf_reader.filters:\n",
    "    vcf_reader.filters['PASS']=vcf_reader.filters[list(vcf_reader.filters.keys())[0]]._make(['PASS','Passed by AutoFilter models'])\n",
    "vcf_writer= vcf.Writer(open(outfile, 'w'), vcf_reader)\n",
    "recdict=vcfdict['query']['recdict']\n",
    "recdict_active=recdict.copy()\n",
    "for i in range(len(recdict)):\n",
    "    record=recdict[i]\n",
    "    record.FILTER=predcodedict[dfraw.loc[i]['ypred']]\n",
    "    if 'FT' in record.genotype(samp).data._asdict():\n",
    "        record.genotype(samp).data=record.genotype(samp).data._replace(FT=record.FILTER)\n",
    "    vcf_writer.write_record(record)\n",
    "    vcf_writer.flush()\n",
    "    i=i+1\n",
    "print('Wrote annotated vcf to '+outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HAP\n",
    "hapfile='/'.join(infile.split('/')[:infile.count('/')])+'/happyout_ph.vcf.gz'#tfile='/igm/projects/FOR_JEFF/germfilt/tm/03062020_noon_noprepy_batch_1_giab_4/applied_granular_train_031720_afternoon_filt_happed.vcf.gz'\n",
    "hapdict=f.grab_happy_vcf_new(hapfile)\n",
    "hapdat_raw=hapdict['df']\n",
    "hapdat=hapdat_raw[~(hapdat_raw['ALT_list'].apply(len)==0)].copy()\n",
    "hapdat['ALT']=hapdat['ALT_list'].apply(lambda x: ';'.join([str(y) for y in x]))\n",
    "hapdat.loc[hapdat.BD_TRUTH.isnull(),'BD_TRUTH']='X'\n",
    "hapdat.loc[hapdat.BD_QUERY.isnull(),'BD_QUERY']='X'\n",
    "hapdat['y']=0\n",
    "hapdat.loc[(hapdat.BD_QUERY=='TP'),'y']=1\n",
    "hapdat.loc[(hapdat.BD_TRUTH=='FN') & (hapdat.BD_QUERY=='FP'),'y']=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## JOIN TO HAP\n",
    "filtcols=['ypred_'+samp,'tranchflag_1','tranchflag_2','tranchflag_both','gatkflag','lqflag','glqflag','lqtflag']\n",
    "filtcols=['ypred_'+samp,'yprob_'+samp]\n",
    "refcols=['CHROM','POS','REF','ALT']\n",
    "joindat=pd.merge(left=df[refcols+['vartype']+filtcols],right=hapdat,\n",
    "                 on=['CHROM','POS','REF','ALT'],how='inner').rename(columns={x+'_'+samp:x for x in ['ypred','yprob']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vartype</th>\n",
       "      <th>ypred</th>\n",
       "      <th>y</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D16_PLUS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D16_PLUS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D1_5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D1_5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D1_5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D1_5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D6_15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D6_15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I16_PLUS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I1_5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I1_5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I6_15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I6_15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SNP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SNP</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SNP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SNP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     vartype  ypred  y      n\n",
       "0   D16_PLUS      1  0      2\n",
       "1   D16_PLUS      1  1     53\n",
       "2       D1_5      0  0    290\n",
       "3       D1_5      0  1      2\n",
       "4       D1_5      1  0    204\n",
       "5       D1_5      1  1   2129\n",
       "6      D6_15      1  0      7\n",
       "7      D6_15      1  1    186\n",
       "8   I16_PLUS      1  1     56\n",
       "9       I1_5      1  0     30\n",
       "10      I1_5      1  1   2221\n",
       "11     I6_15      1  0      5\n",
       "12     I6_15      1  1    177\n",
       "13       SNP      0  0     73\n",
       "14       SNP      0  1      5\n",
       "15       SNP      1  0     61\n",
       "16       SNP      1  1  50460"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joindat.assign(n=1).groupby(['vartype','ypred','y'])['n'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTRACT FILTS\n",
    "dfcur=dfraw[dfraw.ALT_list.apply(len)==1].copy()\n",
    "dfcur['filtstring']=dfcur['FILTER'].apply(lambda x: ';'.join(x))\n",
    "dfcur['tranchflag_1']=1-1*(dfcur.filtstring.str.contains('VQSRTrancheSNP99.00'))\n",
    "dfcur['tranchflag_2']=1-1*(dfcur.filtstring.str.contains('VQSRTrancheSNP99.90'))\n",
    "dfcur['tranchflag_both']=dfcur['tranchflag_1']*dfcur['tranchflag_2']\n",
    "dfcur['gatkflag']=1-1*(dfcur.filtstring.str.contains('gatkRecommendIndelFilter'))\n",
    "dfcur['lqflag']=1-1*(dfcur.filtstring.str.contains('LowQual'))\n",
    "dfcur['glqflag']=dfcur['gatkflag']*dfcur['lqflag']\n",
    "dfcur['lqtflag']=dfcur['tranchflag_2']*dfcur['lqflag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## JOIN\n",
    "filtcols=['ypred_'+samp,'tranchflag_1','tranchflag_2','tranchflag_both','gatkflag','lqflag','glqflag','lqtflag']\n",
    "refcols=['CHROM','POS','REF','ALT']\n",
    "joindat=pd.merge(left=dfcur[~dfcur.ALT.isnull()][refcols+['vartype']+filtcols],right=hapdat,\n",
    "                 on=['CHROM','POS','REF','ALT'],how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joindat['ypred_ext']=joindat['lqtflag']\n",
    "joindat.loc[joindat.vartype == 'INDEL','ypred_ext']=joindat.loc[joindat.vartype == 'INDEL']['glqflag']\n",
    "joindat['ypred_loc']=joindat['ypred_'+samp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agdat=joindat.assign(n=1).groupby(['vartype','y','ypred_loc','ypred_ext'])['n'].count().reset_index()\n",
    "for x in ['loc','ext']:\n",
    "    agdat['TP_'+x]=agdat['ypred_'+x]*agdat['y']*agdat['n']\n",
    "    agdat['FP_'+x]=agdat['ypred_'+x]*(1-agdat['y'])*agdat['n']\n",
    "    agdat['TN_'+x]=(1-agdat['ypred_'+x])*(1-agdat['y'])*agdat['n']\n",
    "    agdat['FN_'+x]=(1-agdat['ypred_'+x])*agdat['y']*agdat['n']\n",
    "outcols=[x+'_'+y for x in ['TP','FP','FN','TN'] for y in ['loc','ext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagdat=agdat.groupby('vartype').agg({x:'sum' for x in outcols}).reset_index()\n",
    "truthvars=['TP','FP','FN','TN']\n",
    "tempdict={}\n",
    "for x in ['loc','ext']:\n",
    "    tempdict[x]=cagdat[['vartype']+[y+'_'+x for y in truthvars]].rename(columns={y+'_'+x:y for y in truthvars}).assign(filt=x)\n",
    "#agdat.vartype.unique()\n",
    "#{x:'sum' for x in outcols}\n",
    "sdat=pd.concat(tempdict,ignore_index=True)[['vartype','filt']+truthvars]\n",
    "sdat['recall']=sdat['TP']*1.0/(sdat['TP']+sdat['FN'])\n",
    "sdat['precision']=sdat['TP']*1.0/(sdat['TP']+sdat['FP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax=plt.subplots()\n",
    "for filt in ['loc','ext']:\n",
    "    plotdat=sdat[sdat.filt==filt]\n",
    "    plt.scatter(plotdat.precision,plotdat.recall,label=filt)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rnaenv]",
   "language": "python",
   "name": "conda-env-rnaenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
